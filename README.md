# üöÄ Multilingual RAG System (Bengali-English)

A comprehensive Retrieval-Augmented Generation system designed for Bengali and English queries, specifically optimized for HSC Bangla 1st Paper content and educational materials.

## ‚ú® Features

### üåê Core Capabilities
- **Multilingual Support**: Seamless handling of Bengali and English queries
- **PDF Processing**: Advanced Bengali text extraction from PDF documents
- **Semantic Search**: Context-aware document retrieval using multilingual embeddings
- **Conversation Memory**: Maintains chat history and context across interactions
- **Real-time Processing**: Fast query processing with confidence scoring

### üéØ Bonus Features
- **REST API**: Complete FastAPI-based web service with OpenAPI documentation
- **Comprehensive Evaluation**: Advanced metrics for groundedness, relevance, and quality
- **Industry Integration**: Support for multiple vector databases and LLM providers
- **Performance Analytics**: Detailed system monitoring and performance metrics

## üèóÔ∏è Architecture

```
User Query (EN/BN) ‚Üí Language Detection ‚Üí Embedding Generation ‚Üí Vector Search
                                                                        ‚Üì
Response Generation ‚Üê Context Assembly ‚Üê Chunk Retrieval ‚Üê Similarity Matching
        ‚Üì
Conversation Memory ‚Üê Confidence Scoring ‚Üê Answer Validation
```

## üöÄ Quick Start

### Prerequisites
- Python 3.8+
- 4GB+ RAM (for embedding models)
- 2GB+ disk space

### Installation

1. **Clone and Setup**
```bash
git clone https://github.com/emonhossennn/multilingual-rag-system.git
cd multilingual-rag-system
```

2. **Create Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate     # Windows
```

3. **Install Dependencies**
```bash
pip install -r requirements.txt
```

4. **Environment Configuration**
```bash
cp .env.example .env
# Edit .env with your API keys (optional)
```

### üéÆ Usage Modes

#### 1. Interactive Demo
```bash
python main.py demo
```
- Real-time Q&A in Bengali/English
- Automatic sample data loading
- Conversation history tracking

#### 2. REST API Server
```bash
python main.py api
```
- Full REST API at `http://localhost:8000`
- Interactive docs at `http://localhost:8000/docs`
- Production-ready with async support

#### 3. Document Processing
```bash
python main.py process data/your-document.pdf
```
- Batch PDF processing
- Automatic text extraction and chunking
- Vector database indexing

#### 4. System Evaluation
```bash
python main.py evaluate
```
- Comprehensive performance analysis
- Multiple evaluation metrics
- Detailed reporting

## üìñ API Documentation

### Core Endpoints

#### Chat Query
```http
POST /chat
Content-Type: application/json

{
  "query": "‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?",
  "conversation_id": "user_session_123",
  "include_context": true
}
```

**Response:**
```json
{
  "answer": "‡¶∂‡ßÅ‡¶Æ‡ßç‡¶≠‡ßÅ‡¶®‡¶æ‡¶•",
  "confidence_score": 0.92,
  "processing_time": 0.45,
  "query_language": "bengali",
  "retrieved_chunks": [...],
  "sources": ["sample_data"],
  "conversation_id": "user_session_123",
  "timestamp": "2024-01-15T10:30:00Z"
}
```

#### System Health
```http
GET /health
```

#### Upload Document
```http
POST /upload
Content-Type: multipart/form-data

file: your-document.pdf
metadata: {"category": "literature", "subject": "bangla"}
```

#### Run Evaluation
```http
POST /evaluate
Content-Type: application/json

{
  "test_queries": [...],
  "include_detailed_results": true
}
```

## üß™ Evaluation Metrics

### Groundedness (0-1)
Measures how well answers are supported by retrieved context:
- **Keyword Overlap**: Direct word matching between answer and context
- **Quote Detection**: Identification of direct quotes from source material
- **Semantic Similarity**: Conceptual alignment between answer and context

### Relevance (0-1)
Evaluates quality of document retrieval:
- **Similarity Scores**: Vector similarity between query and retrieved chunks
- **Query-Document Overlap**: Keyword matching between query and documents
- **Ranking Quality**: Position-based relevance scoring

### Answer Quality (0-1)
Comprehensive answer assessment:
- **Length Appropriateness**: Optimal answer length for question type
- **Language Consistency**: Proper language detection and usage
- **Completeness**: Whether answer fully addresses the question
- **Coherence**: Logical flow and readability

### Performance Metrics
- **Processing Time**: Query response latency
- **Throughput**: Queries processed per second
- **Success Rate**: Percentage of successful query processing
- **Resource Usage**: Memory and CPU utilization

## üéØ Sample Queries & Expected Results

### Bengali Literature Questions
```
Q: ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?
A: ‡¶∂‡ßÅ‡¶Æ‡ßç‡¶≠‡ßÅ‡¶®‡¶æ‡¶•
Confidence: 0.95

Q: ‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?
A: ‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶ï‡ßá
Confidence: 0.88

Q: ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?
A: ‡ßß‡ß´ ‡¶¨‡¶õ‡¶∞
Confidence: 0.92
```

### Cross-Language Queries
```
Q: Who is referred to as a good man in Anupam's language?
A: Shumbhunath
Confidence: 0.87

Q: What was Kalyani's age at marriage?
A: 15 years
Confidence: 0.90
```

### Grammar Questions
```
Q: ‡¶∏‡¶®‡ßç‡¶ß‡¶ø ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡ßá?
A: ‡¶¶‡ßÅ‡¶ü‡¶ø ‡¶¨‡¶∞‡ßç‡¶£‡ßá‡¶∞ ‡¶Æ‡¶ø‡¶≤‡¶®‡¶ï‡ßá ‡¶∏‡¶®‡ßç‡¶ß‡¶ø ‡¶¨‡¶≤‡ßá
Confidence: 0.85
```

## üîß Configuration

### Environment Variables
```bash
# Core Configuration
VECTOR_DB_PATH=./chroma_db
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
CHUNK_SIZE=512
CHUNK_OVERLAP=50
MAX_RETRIEVED_CHUNKS=5

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=True

# Optional: External LLM Integration
OPENAI_API_KEY=your_openai_key
PINECONE_API_KEY=your_pinecone_key
```

### Advanced Configuration
```python
# Custom RAG system initialization
rag_system = MultilingualRAGSystem(
    persist_directory="./custom_db",
    embedding_model="custom-model-name",
    chunk_size=256,
    chunk_overlap=25,
    max_retrieved_chunks=3
)
```

## üß™ Testing

### Run All Tests
```bash
pytest tests/ -v
```

### Test Categories
```bash
# Unit tests
pytest tests/test_rag_system.py -v

# API tests
pytest tests/test_api.py -v

# Integration tests
pytest tests/ -k "integration" -v
```

### Test Coverage
```bash
pip install pytest-cov
pytest tests/ --cov=src --cov-report=html
```

## üìä Performance Benchmarks

### Typical Performance (on standard hardware)
- **Query Processing**: 0.3-1.5 seconds
- **Document Indexing**: 2-5 seconds per page
- **Memory Usage**: 1-2GB for standard models
- **Throughput**: 10-50 queries per second

### Optimization Tips
1. **Use GPU**: Significantly faster embedding generation
2. **Batch Processing**: Process multiple documents together
3. **Chunk Size Tuning**: Balance between context and speed
4. **Model Selection**: Smaller models for faster inference

## üîå Integration Examples

### Python Integration
```python
from src.rag_system import MultilingualRAGSystem

# Initialize system
rag = MultilingualRAGSystem()

# Add documents
rag.index_document("data/bangla-literature.pdf")

# Query system
response = rag.query("‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶ö‡¶∞‡¶ø‡¶§‡ßç‡¶∞ ‡¶ï‡ßá‡¶Æ‡¶®?")
print(f"Answer: {response.answer}")
print(f"Confidence: {response.confidence_score}")
```

### API Integration
```python
import requests

# Query via API
response = requests.post("http://localhost:8000/chat", json={
    "query": "‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?",
    "conversation_id": "my_session"
})

result = response.json()
print(f"Answer: {result['answer']}")
```

### Evaluation Integration
```python
from evaluation.evaluator import RAGEvaluator
from evaluation.test_datasets import create_test_dataset

# Run evaluation
evaluator = RAGEvaluator(rag_system)
test_queries = create_test_dataset()
results = evaluator.comprehensive_evaluation(test_queries)

print(f"Average Groundedness: {results['aggregate_metrics']['avg_groundedness']:.3f}")
```

## üõ†Ô∏è Tools, Libraries & Packages Used

### Core Dependencies
- **sentence-transformers==2.2.2**: Multilingual embedding generation
- **chromadb==0.4.15**: Vector database for semantic search
- **PyMuPDF==1.23.5**: PDF text extraction with Bengali support
- **langdetect==1.0.9**: Automatic language detection
- **fastapi==0.104.1**: Modern REST API framework
- **uvicorn==0.24.0**: ASGI server for API deployment
- **nltk==3.8.1**: Natural language processing utilities
- **numpy==1.24.3**: Numerical computations for embeddings
- **scikit-learn==1.3.0**: Machine learning utilities and metrics

### Development & Testing
- **pytest==7.4.3**: Testing framework
- **black==23.9.1**: Code formatting
- **flake8==6.1.0**: Code linting
- **python-dotenv==1.0.0**: Environment variable management

### Optional Integrations
- **openai==1.3.5**: OpenAI API integration
- **requests==2.31.0**: HTTP client for external APIs
- **matplotlib==3.7.2**: Visualization for evaluation
- **seaborn==0.12.2**: Statistical plotting

## üìã Technical Implementation Details

For detailed technical documentation including:
- PDF extraction methodology and challenges
- Chunking strategy rationale
- Embedding model selection criteria
- Similarity comparison methods
- Query handling for vague/missing context
- Performance optimization strategies

**See**: [TECHNICAL_DOCUMENTATION.md](TECHNICAL_DOCUMENTATION.md)

## üõ†Ô∏è Development

### Project Structure
```
multilingual-rag-system/
‚îú‚îÄ‚îÄ src/                    # Core RAG system
‚îÇ   ‚îú‚îÄ‚îÄ rag_system.py      # Main system orchestrator
‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py    # ChromaDB integration
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py      # Multilingual embeddings
‚îÇ   ‚îú‚îÄ‚îÄ memory.py          # Conversation management
‚îÇ   ‚îú‚îÄ‚îÄ chunker.py         # Document processing
‚îÇ   ‚îú‚îÄ‚îÄ pdf_processor.py   # PDF text extraction
‚îÇ   ‚îî‚îÄ‚îÄ llm_client.py      # LLM integration
‚îú‚îÄ‚îÄ api/                   # REST API
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # FastAPI application
‚îÇ   ‚îî‚îÄ‚îÄ models.py         # Pydantic models
‚îú‚îÄ‚îÄ evaluation/           # Evaluation system
‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py     # Main evaluator
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py       # Evaluation metrics
‚îÇ   ‚îî‚îÄ‚îÄ test_datasets.py # Test data management
‚îú‚îÄ‚îÄ tests/               # Test suite
‚îú‚îÄ‚îÄ main.py             # CLI entry point
‚îî‚îÄ‚îÄ requirements.txt    # Dependencies
```

### Adding New Features

1. **New Evaluation Metric**
```python
# evaluation/metrics.py
class CustomMetric(BaseMetric):
    def calculate(self, **kwargs) -> float:
        # Your metric implementation
        return score
```

2. **New API Endpoint**
```python
# api/main.py
@app.post("/custom-endpoint")
async def custom_endpoint(request: CustomRequest):
    # Your endpoint implementation
    return response
```

3. **New Document Processor**
```python
# src/processors/custom_processor.py
class CustomProcessor:
    def process(self, file_path: str) -> str:
        # Your processing logic
        return extracted_text
```

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Add tests for new functionality
5. Run the test suite (`pytest tests/ -v`)
6. Commit your changes (`git commit -m 'Add amazing feature'`)
7. Push to the branch (`git push origin feature/amazing-feature`)
8. Open a Pull Request

### Code Style
- Follow PEP 8 guidelines
- Use type hints where possible
- Add docstrings for all public functions
- Maintain test coverage above 80%

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **Sentence Transformers**: Multilingual embedding models
- **ChromaDB**: Vector database infrastructure
- **FastAPI**: Modern web framework
- **PyMuPDF**: PDF processing capabilities
- **HSC Bangla Curriculum**: Educational content inspiration

## üìû Support

- **Documentation**: Check the `/docs` endpoint when running the API
- **Issues**: Report bugs via GitHub Issues
- **Discussions**: Join community discussions
- **Email**: Contact the development team

## üîÆ Roadmap

### Version 2.0 (Planned)
- [ ] Advanced LLM integration (GPT-4, Claude)
- [ ] Real-time collaborative features
- [ ] Enhanced Bengali NLP processing
- [ ] Mobile app integration
- [ ] Advanced analytics dashboard

### Version 1.5 (In Progress)
- [ ] Improved evaluation metrics
- [ ] Better error handling
- [ ] Performance optimizations
- [ ] Extended language support

---

**Built with ‚ù§Ô∏è for Bengali education and multilingual AI**#   m u l t i l i n g u a l - r a g - s y s t e m  
 